# 7 Best Practices for MongoDB Query Optimization in Node.js | by Arunangshu Das | Mar, 2025 | Medium

# 7 Best Practices for MongoDB Query Optimization in Node.js

[

![Arunangshu Das](https://miro.medium.com/v2/resize:fill:64:64/1*2bvgMQpfaXC6QJlXSnR3tg.jpeg)





](/?source=post_page---byline--fb9850389e36---------------------------------------)

[Arunangshu Das](/?source=post_page---byline--fb9850389e36---------------------------------------)

Follow

4 min read

·

Mar 25, 2025

24

Listen

Share

More

![7 Best Practices for MongoDB Query Optimization in Node.js](https://miro.medium.com/v2/resize:fit:1250/1*aAZLSPRNedUFWsMYY7zCTQ.png)
7 Best Practices for MongoDB Query Optimization in Node.js

When working with MongoDB in a Node.js application, performance optimization should be a top priority. While MongoDB is a highly scalable NoSQL database, inefficient queries can slow down your app, increase server costs, and create bottlenecks.

# 1\. Use Indexes Wisely for Faster Lookups

Indexes are the backbone of MongoDB performance. Without indexes, queries perform a **collection scan**, meaning MongoDB has to check every document — this is painfully slow for large datasets.

# How to Create an Index

Use the `createIndex` method to speed up queries:

const { MongoClient } = require("mongodb");  
  
async function createIndex() {  
  const client = new MongoClient("mongodb://localhost:27017");  
  await client.connect();  
  const db = client.db("ecommerce");  
  const products = db.collection("products");  
  
  // Create an index on the 'category' field  
  await products.createIndex({ category: 1 });  
  
  console.log("Index created!");  
  await client.close();  
}  
  
createIndex();

# Best Practices for Indexing

-   **Always index fields used in** `**find()**`**,** `**sort()**`**, and** `**group()**` **queries.**
-   **Use compound indexes** when filtering by multiple fields. For example, if you frequently query by `category` and `price`, create an index on `{ category: 1, price: -1 }`.
-   **Avoid over-indexing.** While indexes speed up read queries, they also slow down write operations since every insert or update must update the index.

# 2\. Optimize Query Patterns to Reduce Unnecessary Data Fetching

Fetching unnecessary data increases load time and resource consumption. Always **query for only the fields you need.**

# Example of Selecting Specific Fields

Instead of fetching the entire document:

const product = await products.findOne({ category: "electronics" });

Use **projection** to return only required fields:

const product = await products.findOne(  
  { category: "electronics" },  
  { projection: { name: 1, price: 1, \_id: 0 } }  
);

Result:

{ "name": "Laptop", "price": 1200 }

This approach **reduces data transfer**, leading to better performance.

# 3\. Avoid Large `$in` Queries and Use `$or` for Better Performance

If you’re filtering a collection with an `$in` query on a large dataset, MongoDB may struggle to optimize it. Instead, consider `$or` or **index-based filtering**.

# Bad Query Using `$in`

const users = await usersCollection.find({ country: { $in: \["US", "UK", "CA"\] } }).toArray();

Instead, **optimize it with** `**$or**`:

const users = await usersCollection.find({  
  $or: \[{ country: "US" }, { country: "UK" }, { country: "CA" }\],  
}).toArray();

MongoDB can better optimize individual indexed fields with `$or` queries compared to `$in`.

# 4\. Use Pagination Instead of `skip()` for Large Datasets

When paginating, avoid using `.skip(n)`, as it forces MongoDB to iterate through `n` documents before returning results—this slows down performance.

# The Better Approach: Pagination with `_id`

Instead of:

const products = await productsCollection.find().skip(1000).limit(20).toArray();

Use **range-based pagination** with `_id`:

const lastId = "660f1f2e5c2135c29d1c1234"; // Last \`\_id\` from the previous page  
const products = await productsCollection  
  .find({ \_id: { $gt: lastId } })  
  .limit(20)  
  .toArray();

This method is **faster and more efficient** because MongoDB can leverage indexes.

# 5\. Use `lean()` Queries with Mongoose for Performance Boost

If you’re using Mongoose, the `.lean()` method removes unnecessary document overhead, making queries faster.

**Without** `**.lean()**`**:**

const users = await User.find({ isActive: true }); // Returns full Mongoose documents

With `.lean()`:

const users = await User.find({ isActive: true }).lean(); // Returns plain JavaScript objects

This is **20–30% faster** for read-heavy operations.

# 6\. Monitor Slow Queries Using `explain()`

MongoDB has a built-in way to analyze queries: `explain()`.

# Example Usage

const explainOutput = await productsCollection  
  .find({ category: "electronics" })  
  .explain("executionStats");  
  
console.log(JSON.stringify(explainOutput, null, 2));

Key metrics to watch:

-   `**nReturned**` – Number of documents returned.
-   `**totalDocsExamined**` – If this is high, your query needs an index.
-   `**executionTimeMillis**` – Total query execution time.

# 7\. Enable Query Caching with Redis

For read-heavy applications, caching frequent queries **reduces database load** and **boosts performance**. Use Redis to cache query results.

# Example: MongoDB with Redis

const Redis = require("ioredis");  
const redis = new Redis();  
  
async function getProducts() {  
  const cacheKey = "products:electronics";  
  
  // Check Redis cache first  
  const cachedData = await redis.get(cacheKey);  
  if (cachedData) return JSON.parse(cachedData);  
  
  // Query MongoDB if not found in cache  
  const products = await productsCollection.find({ category: "electronics" }).toArray();  
  
  // Store result in Redis for 10 minutes  
  await redis.setex(cacheKey, 600, JSON.stringify(products));  
  
  return products;  
}

This **reduces database queries** and **speeds up responses** for frequently requested data.

# Quick Recap of Best Practices:

→ **Use Indexes Wisely** — Avoid full collection scans.  
→ **Optimize Query Patterns** — Fetch only the necessary fields.  
→ **Use** `**$or**` **Instead of Large** `**$in**` **Queries** – More efficient filtering.  
→ **Paginate Efficiently** – Avoid `.skip()`, use `_id` for faster queries.  
→ **Use** `**.lean()**` **with Mongoose** – Get plain objects instead of full documents.  
→ **Monitor Slow Queries with** `**explain()**` – Identify bottlenecks.  
→ **Implement Caching with Redis** – Reduce DB load and speed up responses.

**You may also like:**

1.  [**10 Common Mistakes with Synchronous Code in Node.js**](/10-common-mistakes-with-synchronous-code-in-node-js-8b55929dd3e3)
2.  [**Why 85% of Developers Use Express.js Wrongly**](/why-85-of-developers-use-express-js-wrongly-8c9c6f380fce)
3.  [**Implementing Zero-Downtime Deployments in Node.js**](/implementing-zero-downtime-deployments-in-node-js-8d5678e8cfea)
4.  [**10 Common Memory Management Mistakes in Node.js**](/10-common-memory-management-mistakes-in-node-js-1d26af191873)
5.  [**5 Key Differences Between ^ and ~ in package.json**](/5-key-differences-between-and-in-package-json-d97b728ec395)
6.  [**Scaling Node.js for Robust Multi-Tenant Architectures**](/scaling-node-js-for-robust-multi-tenant-architectures-feecb05de7b7)
7.  [**6 Common Mistakes in Domain-Driven Design (DDD) with Express.js**](/6-common-mistakes-in-domain-driven-design-ddd-with-express-js-26560ec64661)
8.  [**10 Performance Enhancements in Node.js Using V8**](/10-performance-enhancements-in-node-js-using-v8-9afc5a8ceca1)
9.  [**Can Node.js Handle Millions of Users?**](https://blog.arunangshudas.com/can-node-js-handle-millions-of-users/)
10.  [**Express.js Secrets That Senior Developers Don’t Share**](/express-js-secrets-that-senior-developers-dont-share-b2979bd7439a)

**Read more blogs from** [**Here**](https://blog.arunangshudas.com/)

Share your experiences in the comments, and let’s discuss how to tackle them!

**Follow me on** [**Linkedin**](https://www.linkedin.com/in/arunangshu-das/)

## Embedded Content

---